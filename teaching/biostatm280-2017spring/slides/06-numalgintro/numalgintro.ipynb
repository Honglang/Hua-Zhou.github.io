{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical algebra: introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The first big chunk of this course is numerical linear algebra.\n",
    "\n",
    "* Topics in numerical algebra: \n",
    "    - BLAS  \n",
    "    - solve linear equations $\\mathbf{A} \\mathbf{x} = \\mathbf{b}$\n",
    "    - regression computations $\\mathbf{X}^T \\mathbf{X} \\beta = \\mathbf{X}^T \\mathbf{y}$  \n",
    "    - eigen-problems $\\mathbf{A} \\mathbf{x} = \\lambda \\mathbf{x}$  \n",
    "    - generalized eigen-problems $\\mathbf{A} \\mathbf{x} = \\lambda \\mathbf{B} \\mathbf{x}$  \n",
    "    - singular value decompositions $\\mathbf{A} = \\mathbf{U} \\Sigma \\mathbf{V}^T$  \n",
    "    - iterative methods  \n",
    "\n",
    "* Except for the iterative methods, most of these numerical linear algebra tasks are implemented in the BLAS and LAPACK libraries. Our major **goal** is to  \n",
    "    0. know the computational cost (flop count) of each task\n",
    "    0. be familiar with the BLAS and LAPACK functions (what they do)  \n",
    "    0. do _not_ re-invent wheels by implementing these subroutines by yourself  \n",
    "    0. apply appropriate numerical algebra tools to various statistical problems \n",
    "\n",
    "* All high-level languages (R, Matlab, Julia) call BLAS and LAPACK for numerical linear algebra. Julia offers more flexibility by exposing interfaces to many BLAS/LAPACK subroutines directly. See [documentation](https://docs.julialang.org/en/stable/stdlib/linalg/?highlight=blas#module-Base.LinAlg.BLAS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLAS\n",
    "\n",
    "* BLAS stands for _basic linear algebra subprograms_. \n",
    "\n",
    "* See [netlib](http://www.netlib.org/blas/) for a complete listing of standardized BLAS functions.\n",
    "\n",
    "* There are three levels of BLAS functions.\n",
    "    - Level 1: vector operation\n",
    "    - Level 2: matrix-vector operation\n",
    "    - Level 3: matrix-matrix operation\n",
    "\n",
    "| Level | Example Operation                      | Name        | Dimension                                 | Flops |\n",
    "|-------|----------------------------------------|-------------|-------------------------------------------|-------|\n",
    "| 1     | $\\alpha \\gets \\mathbf{x}^T \\mathbf{y}$ | dot product | $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$ | $2n$  |\n",
    "|       | $\\mathbf{y} \\gets \\mathbf{y} + \\alpha \\mathbf{x}$ |  saxpy           |  $\\alpha \\in \\mathbb{R}$, $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$ |  $2n$    |\n",
    "| 2     | $\\mathbf{y} \\gets \\mathbf{y} + \\mathbf{A} \\mathbf{x}$ |  gaxpy           |  $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$, $\\mathbf{x} \\in \\mathbb{R}^n$, $\\mathbf{y} \\in \\mathbb{R}^m$                                     |  $2mn$     |\n",
    "|       | $\\mathbf{A} \\gets \\mathbf{A} + \\mathbf{y} \\mathbf{x}^T$ | rank one update            |    $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$, $\\mathbf{x} \\in \\mathbb{R}^n$, $\\mathbf{y} \\in \\mathbb{R}^m$                                       | $2mn$      |\n",
    "| 3     | $\\mathbf{C} \\gets \\mathbf{C} + \\mathbf{A} \\mathbf{B}$                                       |  matrix multiplication           |  $\\mathbf{A} \\in \\mathbb{R}^{m \\times p}$, $\\mathbf{B} \\in \\mathbb{R}^{p \\times n}$, $\\mathbf{C} \\in \\mathbb{R}^{m \\times n}$                                         | $2mnp$      |\n",
    "\n",
    "* Typical BLAS functions support single precision (S), double precision (D), complex (C), and double complex (Z). \n",
    "\n",
    "* Some operations appear as level-3 but indeed are level-2.  \n",
    "    - A common operation in statistics is column scaling or row scaling\n",
    "    $$ A = AD $$\n",
    "    $$ A = DA $$\n",
    "    - These are essentially level-2 operation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  30.52 MiB\n",
       "  allocs estimate:  2\n",
       "  --------------\n",
       "  minimum time:     101.338 ms (3.51% GC)\n",
       "  median time:      102.322 ms (3.50% GC)\n",
       "  mean time:        104.217 ms (4.26% GC)\n",
       "  maximum time:     145.673 ms (30.60% GC)\n",
       "  --------------\n",
       "  samples:          48\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "n = 2000\n",
    "\n",
    "A = rand(n, n)\n",
    "d = rand(n)  # d vector\n",
    "D = diagm(d) # diagonal matrix with d as diagonal\n",
    "\n",
    "# this is calling BLAS routine for matrix multiplication\n",
    "@benchmark A * D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  30.53 MiB\n",
       "  allocs estimate:  68\n",
       "  --------------\n",
       "  minimum time:     20.959 ms (16.29% GC)\n",
       "  median time:      24.166 ms (15.51% GC)\n",
       "  mean time:        24.399 ms (16.75% GC)\n",
       "  maximum time:     77.463 ms (71.77% GC)\n",
       "  --------------\n",
       "  samples:          205\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columnwise scaling\n",
    "@benchmark scale(A, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  30.52 MiB\n",
       "  allocs estimate:  3\n",
       "  --------------\n",
       "  minimum time:     19.813 ms (1.37% GC)\n",
       "  median time:      23.585 ms (16.13% GC)\n",
       "  mean time:        23.873 ms (17.02% GC)\n",
       "  maximum time:     71.266 ms (71.53% GC)\n",
       "  --------------\n",
       "  samples:          210\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another way for columnwise scaling\n",
    "@benchmark A * Diagonal(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory hierarchy and BLAS level-3 fraction\n",
    "\n",
    "> Key to high performance is effective use of memory hierarchy. True on all architectures.\n",
    "\n",
    "* Flops is not the sole determinant of algorithm efficiency. Another important factor is data movement through the memory hierarchy.\n",
    "\n",
    "<img src=\"http://tssdr1.thessdreview1.netdna-cdn.com/wp-content/uploads/2013/10/Base-Open.png\" width=\"500\" align=\"center\">\n",
    "\n",
    "<img src=\"http://hothardware.com/ContentImages/NewsItem/34743/content/Intel-Skylake-Graphics-Gen-9-Block-Diag.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "<img src=\"http://images.bit-tech.net/content_images/2007/11/the_secrets_of_pc_memory_part_1/hei.png\" width=\"500\" align=\"center\">\n",
    "\n",
    "* Can we keep CPU cores busy with enough deliveries of matrix data and ship the results to memory fast enough to avoid backlog?  \n",
    "Answer: use **high-level BLAS** as much as possible.\n",
    "\n",
    "| BLAS                                                           | Dimension                                                                           | Mem. Refs. | Flops  | Ratio |\n",
    "|----------------------------------------------------------------|-------------------------------------------------------------------------------------|------------|--------|-------|\n",
    "| Level 1: $\\mathbf{y} \\gets \\mathbf{y} + \\alpha \\mathbf{x}$     | $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$                                           | $3n$       | $2n$   | 3:3   |\n",
    "| Level 2: $\\mathbf{y} \\gets \\mathbf{y} + \\mathbf{A} \\mathbf{x}$ | $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$, $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ | $n^2$      | $2n^2$ | 1:2   |\n",
    "| Level 3: $\\mathbf{C} \\gets \\mathbf{C} + \\mathbf{A} \\mathbf{B}$ | $\\mathbf{A}, \\mathbf{B}, \\mathbf{C} \\in \\mathbb{R}^{n \\times n}$                    | $4n^2$     | $2n^3$ | $2:n$ |  \n",
    "\n",
    "* BLAS 1 tend to be **memory bandwidth-limited**. E.g., Xeon X5650 CPU has a theoretical throughput of 128 DP GFLOPS but a max memory bandwidth of 32GB/s.\n",
    "\n",
    "* Higher level BLAS (3 or 2) make more effective use of arithmetic logic units (ALU) by keeping them busy.\n",
    "\n",
    "* A distinction between LAPACK and LINPACK (older version of R uses LINPACK) is that LAPACK makes use of higher level BLAS as much as possible (usually by smart partitioning) to increase the so-called **level-3 fraction**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of data layout\n",
    "\n",
    "* Data layout in memory effects execution speed too. It is much faster to move chunks of data in memory than retrieving/writing scattered data.\n",
    "\n",
    "* Storage mode: **column-major** (Fortran, Matlab, R, Julia) vs **row-major** (C/C++).\n",
    "\n",
    "* **Cache line** is the minimum amount of cache which can be loaded and stored to memory.\n",
    "    - x86 CPUs: 64 bytes  \n",
    "    - ARM CPUS: 32 bytes\n",
    "\n",
    "<img src=\"https://patterns.eecs.berkeley.edu/wordpress/wp-content/uploads/2013/04/dense02.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "* Accessing column-major stored matrix by rows causes lots of **cache misses**.\n",
    "\n",
    "* When you call BLAS from C/C++, use the CBLAS library instead of the traditional BLAS library implemented in Fortran.\n",
    "\n",
    "* Take matrix multiplication as an example. \n",
    "$$ \n",
    "\\mathbf{C} \\gets \\mathbf{C} + \\mathbf{A} \\mathbf{B}, \\quad \\mathbf{A} \\in \\mathbb{R}^{m \\times p}, \\mathbf{B} \\in \\mathbb{R}^{p \\times n}, \\mathbf{C} \\in \\mathbb{R}^{m \\times n}.\n",
    "$$\n",
    "Assume the storage is column-major, such as in Julia. There are 6 variants of the algorithms according to the order in the triple loops. We pay attention to the innermost loop, where the vector calculation occurs. \n",
    "    - `jki` or `kji` looping:\n",
    "    ```julia\n",
    "    for i = 1:m\n",
    "        C[i, j] = C[i, j] + A[i, k] * B[k, j]\n",
    "    end\n",
    "    ```  \n",
    "    - `ikj` or `kij` looping:\n",
    "    ```julia\n",
    "    for j = 1:n\n",
    "        C[i, j] = C[i, j] + A[i, k] * B[k, j]\n",
    "    end\n",
    "    ```  \n",
    "    - `ijk` or `jik` looping:\n",
    "    ```julia\n",
    "    for k = 1:p\n",
    "        C[i, j] = C[i, j] + A[i, k] * B[k, j]\n",
    "    end\n",
    "    ```\n",
    "The associated **stride** when accessing the three matrices in memory (assuming column-major storage) is  \n",
    "\n",
    "| Variant        | A Stride | B Stride | C Stride |\n",
    "|----------------|----------|----------|----------|\n",
    "| $jki$ or $kji$ | Unit     | 0        | Unit     |\n",
    "| $ikj$ or $kij$ | 0        | Non-Unit | Non-Unit |\n",
    "| $ijk$ or $jik$ | Non-Unit | Unit     | 0        |\n",
    "\n",
    "Apparently the variants $jki$ or $kji$ are preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition matmul_by_loop!(Array{Float64, 2}, Array{Float64, 2}, Array{Float64, 2}, String) in module Main at In[31]:4 overwritten at In[32]:4.\n"
     ]
    }
   ],
   "source": [
    "function matmul_by_loop!(A::Matrix{Float64}, B::Matrix{Float64}, \n",
    "    C::Matrix{Float64}, order::String)\n",
    "    \n",
    "    m = size(A, 1)\n",
    "    p = size(A, 2)\n",
    "    n = size(B, 2)\n",
    "    \n",
    "    if order == \"jki\"\n",
    "        for j = 1:n, k = 1:p, i = 1:m\n",
    "            C[i, j] += A[i, k] * B[k, j]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if order == \"kji\"\n",
    "        for k = 1:p, j = 1:n, i = 1:m\n",
    "            C[i, j] += A[i, k] * B[k, j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if order == \"ikj\"\n",
    "        for i = 1:m, k = 1:p, j = 1:n\n",
    "            C[i, j] += A[i, k] * B[k, j]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if order == \"kij\"\n",
    "        for k = 1:p, i = 1:m, j = 1:n\n",
    "            C[i, j] += A[i, k] * B[k, j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if order == \"ijk\"\n",
    "        for i = 1:m, j = 1:n, k = 1:p\n",
    "            C[i, j] += A[i, k] * B[k, j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if order == \"jik\"\n",
    "        for j = 1:n, i = 1:m, k = 1:p\n",
    "            C[i, j] += A[i, k] * B[k, j]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "end\n",
    "\n",
    "srand(123)\n",
    "m, n, p = 2000, 100, 2000\n",
    "A = rand(m, n)\n",
    "B = rand(n, p)\n",
    "C = zeros(m, p);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $jki$ and $kji$ looping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     429.365 ms (0.00% GC)\n",
       "  median time:      464.860 ms (0.00% GC)\n",
       "  mean time:        479.010 ms (0.00% GC)\n",
       "  maximum time:     576.146 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          11\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill!(C, 0.0)\n",
    "@benchmark matmul_by_loop!(A, B, C, \"jki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     492.760 ms (0.00% GC)\n",
       "  median time:      573.256 ms (0.00% GC)\n",
       "  mean time:        573.022 ms (0.00% GC)\n",
       "  maximum time:     707.823 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          9\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill!(C, 0.0)\n",
    "@benchmark matmul_by_loop!(A, B, C, \"kji\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ikj$ and $kij$ looping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     2.444 s (0.00% GC)\n",
       "  median time:      2.508 s (0.00% GC)\n",
       "  mean time:        2.508 s (0.00% GC)\n",
       "  maximum time:     2.573 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          2\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill!(C, 0.0)\n",
    "@benchmark matmul_by_loop!(A, B, C, \"ikj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     2.615 s (0.00% GC)\n",
       "  median time:      2.657 s (0.00% GC)\n",
       "  mean time:        2.657 s (0.00% GC)\n",
       "  maximum time:     2.699 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          2\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill!(C, 0.0)\n",
    "@benchmark matmul_by_loop!(A, B, C, \"kij\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ijk$ and $jik$ looping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     1.090 s (0.00% GC)\n",
       "  median time:      1.333 s (0.00% GC)\n",
       "  mean time:        1.257 s (0.00% GC)\n",
       "  maximum time:     1.397 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          5\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill!(C, 0.0)\n",
    "@benchmark matmul_by_loop!(A, B, C, \"ijk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     1.095 s (0.00% GC)\n",
       "  median time:      1.138 s (0.00% GC)\n",
       "  mean time:        1.158 s (0.00% GC)\n",
       "  maximum time:     1.277 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          5\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill!(C, 0.0)\n",
    "@benchmark matmul_by_loop!(A, B, C, \"ijk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Julia wrapper of BLAS function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     4.844 ms (0.00% GC)\n",
       "  median time:      6.862 ms (0.00% GC)\n",
       "  mean time:        6.759 ms (0.00% GC)\n",
       "  maximum time:     11.662 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          735\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill!(C, 0.0)\n",
    "@benchmark Base.LinAlg.BLAS.gemm!('N', 'N', 1.0, A, B, 1.0, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoid memory transactions as much as possible\n",
    "\n",
    "* Transpose or not.  \n",
    "    - Julia is smart to avoid transposing matrix if possible.\n",
    "    - In R, the command `t(A) %*% x` will first transpose `A` then perform matrix multiplication, causing unnecessary memory allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.94 KiB\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     88.529 μs (0.00% GC)\n",
       "  median time:      130.786 μs (0.00% GC)\n",
       "  mean time:        141.644 μs (0.00% GC)\n",
       "  maximum time:     895.696 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srand(123)\n",
    "\n",
    "n = 1000\n",
    "A = rand(n, n)\n",
    "x = rand(n)\n",
    "\n",
    "@benchmark A' * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.94 KiB\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     98.216 μs (0.00% GC)\n",
       "  median time:      126.025 μs (0.00% GC)\n",
       "  mean time:        133.685 μs (0.00% GC)\n",
       "  maximum time:     685.291 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark At_mul_B(A, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Broadcasting](https://docs.julialang.org/en/stable/manual/functions/#dot-syntax-for-vectorizing-functions) in Julia achieves vectorized code without creating intermediate arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  64 bytes\n",
       "  allocs estimate:  3\n",
       "  --------------\n",
       "  minimum time:     68.583 ms (0.00% GC)\n",
       "  median time:      69.665 ms (0.00% GC)\n",
       "  mean time:        70.769 ms (0.00% GC)\n",
       "  maximum time:     78.866 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          71\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srand(123)\n",
    "A = rand(1000, 1000)\n",
    "B = similar(A) # allocate a matrix same size as A\n",
    "\n",
    "@benchmark B .= log.(exp.(asin.(sin.(A))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  30.52 MiB\n",
       "  allocs estimate:  12\n",
       "  --------------\n",
       "  minimum time:     45.258 ms (2.65% GC)\n",
       "  median time:      49.257 ms (4.68% GC)\n",
       "  mean time:        49.358 ms (4.90% GC)\n",
       "  maximum time:     59.911 ms (0.62% GC)\n",
       "  --------------\n",
       "  samples:          102\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark B = log(exp(asin(sin(A))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [View](https://docs.julialang.org/en/stable/stdlib/arrays/#Base.view) avoids creating extra copy of matrix data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  1.91 MiB\n",
       "  allocs estimate:  6\n",
       "  --------------\n",
       "  minimum time:     301.451 μs (0.00% GC)\n",
       "  median time:      420.798 μs (0.00% GC)\n",
       "  mean time:        604.061 μs (21.44% GC)\n",
       "  maximum time:     3.389 ms (60.29% GC)\n",
       "  --------------\n",
       "  samples:          8112\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum entries in a sub-matrix\n",
    "@benchmark sum(A[1:500, 500:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  256 bytes\n",
       "  allocs estimate:  8\n",
       "  --------------\n",
       "  minimum time:     266.879 μs (0.00% GC)\n",
       "  median time:      267.322 μs (0.00% GC)\n",
       "  mean time:        281.743 μs (0.00% GC)\n",
       "  maximum time:     886.228 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1\n",
       "  time tolerance:   5.00%\n",
       "  memory tolerance: 1.00%"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark sum(@view A[1:500, 500:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.1",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
